#!/usr/bin/env python

"""
A simple driver for ingestion of anndata to a TileDB SOMA.

* Invoke this with one argument /path/to/some/somename.h5ad:
  o Output will be ./tiledb-data/somename

* Invoke this with two arguments to specify input anndata HDF5 file
  and output TileDB group.

Nominal immediate-term support is to local disk and S3, although output to tiledb:/...
URIs will be supported.
"""

import argparse
import os
import sys

import tiledb

import tiledbsoma
import tiledbsoma.io
import tiledbsoma.util


# ================================================================
def main():
    parser = argparse.ArgumentParser(
        description="Ingest soma data from anndata/h5ad into TileDB group structure"
    )
    parser.add_argument(
        "-q", "--quiet", help="decrease output verbosity", action="store_true"
    )
    parser.add_argument(
        "--debug", help="increase output verbosity", action="store_true"
    )
    parser.add_argument(
        "-n",
        help="All arguments after flags are treated as input paths",
        action="store_true",
    )
    parser.add_argument(
        "--ingest-mode",
        help="""Write mode (the default) writes all data, creating new layers if the soma already exists.

Resume mode skip data writes if data are within MBRs of the existing soma.
This is useful for continuing after a partial/interrupted previous upload.

Schema-only mode creates groups and array schema, without writing array data.
This is useful as a prep-step for parallel append-ingest of multiple H5ADs to a single soma.""",
        choices=["write", "schema_only", "resume"],
        default=["write"],
        nargs=1,
    )
    parser.add_argument(
        "--update-obs-and-var",
        help="""Updates obs and var from the specified .h5ad file, leaving all other data in place. Useful for
updating schema/compression/etc. within an existing dataset.""",
        action="store_true",
    )
    parser.add_argument(
        "-o",
        help="Specify output directory to contain the somas",
        type=str,
        default="./tiledb-data",
    )
    parser.add_argument(
        "--threads",
        help="Specify max thread-pool workers",
        type=int,
        default=tiledbsoma.SOMAOptions().max_thread_pool_workers,
    )
    parser.add_argument(
        "--soco",
        help="Write the SOMA and also append to a SOMACollection there",
        action="store_true",
    )
    parser.add_argument(
        "-r",
        "--relative",
        help="""
* If `false` then the group will remember the absolute paths of each member array/subgroup. For
ingesting to TileDB Cloud, this is necessary.

* If `true` then the group will have the relative pth of the member. For TileDB Cloud, this
is never the right thing to do. For local-disk storage, this is essential if you want to move
a SOMA to another directory and have it be able access its members.

* If `auto`, then we select `relative=False` if the URI starts with `tiledb://`, else we
select `relative=True`. (This is the default.)
""",
        choices=["true", "false", "auto"],
        nargs=1,
    )
    parser.add_argument(
        "paths",
        type=str,
        help="One for specified input with default output path, or two to specify input and output paths, or multiple input paths if -n is specified",
        nargs="*",
    )
    args = parser.parse_args()

    write_soco = args.soco
    if args.debug:
        tiledbsoma.logging.debug()
    elif args.quiet:
        tiledbsoma.logging.warning()
    # else default is tiledbsoma.logging.info() in our __init__.py

    if args.relative is None:
        rel_member_uris = None
    else:
        relative = args.relative[0]
        if relative == "true":
            rel_member_uris = True
        elif relative == "false":
            rel_member_uris = False
        elif relative == "auto":
            rel_member_uris = None
        else:
            raise Exception(f"Internal coding error in {__file__}")

    soma_options = tiledbsoma.SOMAOptions(
        member_uris_are_relative=rel_member_uris,
        max_thread_pool_workers=args.threads,
    )
    outdir = args.o.rstrip("/")

    if args.n:
        if len(args.paths) < 1:
            parser.print_help(file=sys.stderr)
            sys.exit(1)
        for input_path in args.paths:
            # Example 'anndata/pbmc3k_processed.h5ad' -> 'tiledb-data/pbmc3k_processed'
            output_path = os.path.join(
                outdir, os.path.splitext(os.path.basename(input_path))[0]
            )
            ingest_one(
                input_path=input_path,
                output_path=output_path,
                ingest_mode=args.ingest_mode[0],
                update_obs_and_var=args.update_obs_and_var,
                soma_options=soma_options,
                write_soco=write_soco,
                soco_dir=outdir,
            )
    else:
        if len(args.paths) == 0:
            input_path = "anndata/pbmc-small.h5ad"
            output_path = os.path.join(outdir, "pbmc-small")
            ingest_one(
                input_path=input_path,
                output_path=output_path,
                ingest_mode=args.ingest_mode[0],
                update_obs_and_var=args.update_obs_and_var,
                soma_options=soma_options,
                write_soco=write_soco,
                soco_dir=outdir,
            )
        elif len(args.paths) == 1:
            input_path = args.paths[0]
            # Example 'anndata/pbmc3k_processed.h5ad' -> 'tiledb-data/pbmc3k_processed'
            output_path = os.path.join(
                outdir, os.path.splitext(os.path.basename(input_path))[0]
            )
            ingest_one(
                input_path=input_path,
                output_path=output_path,
                ingest_mode=args.ingest_mode[0],
                update_obs_and_var=args.update_obs_and_var,
                soma_options=soma_options,
                write_soco=write_soco,
                soco_dir=outdir,
            )
        elif len(args.paths) == 2:
            input_path = args.paths[0]
            output_path = args.paths[1]
            ingest_one(
                input_path=input_path,
                output_path=output_path,
                ingest_mode=args.ingest_mode[0],
                update_obs_and_var=args.update_obs_and_var,
                soma_options=soma_options,
                write_soco=write_soco,
                soco_dir=outdir,
            )
        else:
            parser.print_help(file=sys.stderr)
            sys.exit(1)


# ================================================================
def ingest_one(
    *,
    input_path: str,
    output_path: str,
    ingest_mode: str,
    update_obs_and_var: bool,
    soma_options: tiledbsoma.SOMAOptions,
    write_soco: bool,
    soco_dir: str,
):
    assert ingest_mode in tiledbsoma.util.INGEST_MODES

    # Check that the input exists.
    vfs = tiledb.VFS()
    if not vfs.is_file(input_path):
        # Print this neatly and exit neatly, to avoid a multi-line stack trace otherwise.
        tiledbsoma.logging.logger.error(f"Input path not found: {input_path}")
        sys.exit(1)

    # Prepare to write the output.
    # This is for local-disk use only -- for S3-backed tiledb://... URIs we should
    # use tiledb.vfs to remove any priors, and/or make use of a tiledb `overwrite` flag.
    parent = os.path.dirname(output_path.rstrip("/"))
    if parent != "":
        if tiledbsoma.util.is_local_path(parent):
            if not os.path.exists(parent):
                os.mkdir(parent)

    soma = tiledbsoma.SOMA(uri=output_path, soma_options=soma_options)

    if update_obs_and_var:
        if not os.path.exists(output_path):
            raise Exception("Cannot update; doesn't exist yet:", output_path)
        # Do the ingest into TileDB.
        tiledbsoma.io.from_h5ad_update_obs_and_var(
            soma, input_path, ingest_mode=ingest_mode
        )

    else:
        # Do the ingest into TileDB.
        tiledbsoma.io.from_h5ad(soma, input_path, ingest_mode=ingest_mode)

    tiledbsoma.logging.logger.info(f"Complete: {output_path}")

    if write_soco:
        soco = tiledbsoma.SOMACollection(soco_dir, soma_options=soma_options)
        soco.create_unless_exists()
        if not soco.exists():
            raise Exception(f"Could not create SOCO at {soco.uri}")
        soco.add(soma)

        tiledbsoma.logging.logger.info("")
        tiledbsoma.logging.logger.info(
            f"Added SOMA {soma.name} to SOMACollection {soco_dir}"
        )


# ================================================================
if __name__ == "__main__":
    main()
